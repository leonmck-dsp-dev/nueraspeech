{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leonmck-dsp-dev/nueraspeech/blob/main/nueraspeech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LaTtLnEMYUZ-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lalY1_2iYUZ_"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1sjxjWufYUZ_"
      },
      "outputs": [],
      "source": [
        "# Uncomment the line corresponding to your \"runtime type\" to run in Google Colab\n",
        "\n",
        "# CPU:\n",
        "# !pip install pydub torch==1.7.0+cpu torchvision==0.8.1+cpu torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# GPU:\n",
        "# !pip install pydub torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import sys\n",
        "from torchaudio import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import editdistance\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK_nSa0aYUaA",
        "outputId": "fd7a1dfb-d9d8-4ae7-a30a-bbff21f22854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7EM6WlKQYUaA"
      },
      "outputs": [],
      "source": [
        "from torchaudio.datasets import SPEECHCOMMANDS\n",
        "import os\n",
        "\n",
        "\n",
        "class SubsetSC(SPEECHCOMMANDS):\n",
        "    def __init__(self, subset: str = None):\n",
        "        super().__init__(\"./\", download=True)\n",
        "\n",
        "        def load_list(filename):\n",
        "            filepath = os.path.join(self._path, filename)\n",
        "            with open(filepath) as fileobj:\n",
        "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
        "\n",
        "        if subset == \"validation\":\n",
        "            self._walker = load_list(\"validation_list.txt\")\n",
        "        elif subset == \"testing\":\n",
        "            self._walker = load_list(\"testing_list.txt\")\n",
        "        elif subset == \"training\":\n",
        "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
        "            excludes = set(excludes)\n",
        "            self._walker = [w for w in self._walker if w not in excludes]\n",
        "\n",
        "\n",
        "train_set = SubsetSC(\"training\")\n",
        "test_set = SubsetSC(\"testing\")\n",
        "\n",
        "waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "0_rUOAj8YUaA",
        "outputId": "c2994709-f0b3-4006-f613-0fcc6b3b65d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of waveform: torch.Size([1, 16000])\n",
            "Sample rate of waveform: 16000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(\"Shape of waveform: {}\".format(waveform.size()))\n",
        "print(\"Sample rate of waveform: {}\".format(sample_rate))\n",
        "\n",
        "plt.plot(waveform.t().numpy());"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj6_jO85YUaB"
      },
      "outputs": [],
      "source": [
        "labels = sorted(list(set(datapoint[2] for datapoint in train_set)))\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0adiSTjFYUaB"
      },
      "outputs": [],
      "source": [
        "waveform_first, *_ = train_set[0]\n",
        "ipd.Audio(waveform_first.numpy(), rate=sample_rate)\n",
        "\n",
        "waveform_second, *_ = train_set[1]\n",
        "ipd.Audio(waveform_second.numpy(), rate=sample_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWsWgG_xYUaB"
      },
      "source": [
        "The last file is someone saying “visual”.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6AyMcD5YUaB"
      },
      "outputs": [],
      "source": [
        "waveform_last, *_ = train_set[-1]\n",
        "ipd.Audio(waveform_last.numpy(), rate=sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IC172_CtYUaB"
      },
      "outputs": [],
      "source": [
        "new_sample_rate = 8000\n",
        "import torchaudio\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "class SpecAugment:\n",
        "    def __init__(self, freq_mask_param, time_mask_param, num_time_masks=1, num_freq_masks=1):\n",
        "        self.freq_mask_param = freq_mask_param\n",
        "        self.time_mask_param = time_mask_param\n",
        "        self.num_time_masks = num_time_masks\n",
        "        self.num_freq_masks = num_freq_masks\n",
        "\n",
        "    def __call__(self, specs):\n",
        "        augmented_specs = []\n",
        "        for spec in specs:\n",
        "            # Frequency Masking\n",
        "            for _ in range(self.num_freq_masks):\n",
        "                num_freqs, num_frames = spec.shape\n",
        "                f = random.randrange(0, self.freq_mask_param)\n",
        "                f0 = random.randrange(0, num_freqs - f)\n",
        "                spec[f0:f0 + f, :] = 0\n",
        "\n",
        "            # Time Masking\n",
        "            for _ in range(self.num_time_masks):\n",
        "                num_freqs, num_frames = spec.shape\n",
        "                t = random.randrange(0, self.time_mask_param)\n",
        "                t0 = random.randrange(0, num_frames - t)\n",
        "                spec[:, t0:t0 + t] = 0\n",
        "\n",
        "            augmented_specs.append(spec)\n",
        "\n",
        "        return torch.stack(augmented_specs)\n",
        "\n",
        "\n",
        "# 1. Resample\n",
        "resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
        "resampled_waveform = resampler(waveform)\n",
        "\n",
        "# 2. Convert to Mel-spectrogram\n",
        "mel_transform = torchaudio.transforms.MelSpectrogram(sample_rate=new_sample_rate, n_mels=128)\n",
        "mel_spectrogram = mel_transform(resampled_waveform)\n",
        "\n",
        "# 3. Convert to dB scale\n",
        "db_transform = torchaudio.transforms.AmplitudeToDB()\n",
        "db_mel_spectrogram = db_transform(mel_spectrogram)\n",
        "\n",
        "mel_spectrogram_transform = torch.nn.Sequential(\n",
        "    torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate),\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=new_sample_rate, n_mels=128),\n",
        "    torchaudio.transforms.AmplitudeToDB()\n",
        ")\n",
        "\n",
        "# Instantiate and apply\n",
        "spec_augment = SpecAugment(freq_mask_param=30, time_mask_param=30)\n",
        "\n",
        "# Display\n",
        "plt.figure(figsize=(20, 4))\n",
        "plt.imshow(db_mel_spectrogram[0].detach().numpy(), cmap='viridis', origin='lower', aspect='auto')\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Shape of the Mel spectrogram:\", mel_spectrogram.shape)\n",
        "# Listen to the resampled audio\n",
        "ipd.Audio(resampled_waveform.numpy(), rate=new_sample_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEkZYZirYUaB"
      },
      "outputs": [],
      "source": [
        "def label_to_index(word):\n",
        "    # Return the position of the word in labels\n",
        "    return torch.tensor(labels.index(word))\n",
        "\n",
        "def index_to_label(tensor):\n",
        "    # Convert tensor of indices into its string labels\n",
        "    if tensor.dim() == 0:  # If tensor is a scalar\n",
        "        return labels[tensor.item()]\n",
        "    else:  # If tensor is not a scalar\n",
        "        return [labels[index] for index in tensor.cpu().numpy()]\n",
        "\n",
        "\n",
        "word_start = \"yes\"\n",
        "index = label_to_index(word_start)\n",
        "word_recovered = index_to_label(index)\n",
        "\n",
        "print(word_start, \"-->\", index, \"-->\", word_recovered)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10wdIx6tYUaB"
      },
      "outputs": [],
      "source": [
        "def pad_sequence(batch):\n",
        "    # Make all tensor in a batch the same length by padding with zeros\n",
        "    batch = [item.t() for item in batch]\n",
        "    batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=0.)\n",
        "    return batch.permute(0, 2, 1)\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    # A data tuple has the form:\n",
        "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
        "\n",
        "    tensors, targets = [], []\n",
        "\n",
        "    # Gather in lists, and encode labels as indices\n",
        "    for waveform, _, label, *_ in batch:\n",
        "        tensors += [waveform]\n",
        "        targets += [label_to_index(label)]\n",
        "\n",
        "    # Group the list of tensors into a batched tensor\n",
        "    tensors = pad_sequence(tensors)\n",
        "    targets = torch.stack(targets)\n",
        "\n",
        "    return tensors, targets\n",
        "\n",
        "\n",
        "batch_size = 512\n",
        "if device == \"cuda\":\n",
        "    num_workers = 1\n",
        "    pin_memory = True\n",
        "else:\n",
        "    num_workers = 0\n",
        "    pin_memory = False\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=pin_memory,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsC8Qg3a44vA"
      },
      "outputs": [],
      "source": [
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBuxLZQ_yWlr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueraspeech model architecture\n",
        "## Acoustic Model (Convolutional Layers)\n",
        "\n",
        "### Convolutional Neural Networks (CNNs)\n",
        "A convolutional layer employs a set of learnable filters, which are used to spatially convolve with the input data to produce feature maps. Mathematically, for a 1D input $x$ and a filter $h$, convolution is represented as:\n",
        "\n",
        "$$\n",
        "y(t) = (x * h)(t) = \\sum_{a=-\\infty}^{\\infty} x(a)h(t-a)\n",
        "$$\n",
        "\n",
        "### Batch Normalization\n",
        "\n",
        "Batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation.\n",
        "\n",
        "$$\n",
        "\\hat{x} = \\frac{x - \\text{E}[x]}{\\sqrt{\\text{Var}[x]+\\epsilon}}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $\\hat{x}$ is the normalized data.\n",
        "- $\\text{E}[x]$ is the mean of the batch data.\n",
        "- $\\text{Var}[x]$ is the variance of the batch data.\n",
        "- $\\epsilon$ is a small constant to avoid division by zero.\n",
        "\n",
        "---\n",
        "\n",
        "## Recurrent Layers (GRU Layers)\n",
        "\n",
        "### Gated Recurrent Units (GRUs)\n",
        "\n",
        "GRUs are a type of recurrent neural network (RNN) architecture. The GRU uses gating mechanisms (reset gate and update gate) to control the flow of information.\n",
        "\n",
        "$$\n",
        "r_t = \\sigma(W_r x_t + U_r h_{t-1} + b_r)\n",
        "$$\n",
        "$$\n",
        "z_t = \\sigma(W_z x_t + U_z h_{t-1} + b_z)\n",
        "$$\n",
        "$$\n",
        "\\tilde{h}_t = \\tanh(W x_t + r_t \\odot (U h_{t-1} + b) + b')\n",
        "$$\n",
        "$$\n",
        "h_t = (1 - z_t) \\odot h_{t-1} + z_t \\odot \\tilde{h}_t\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $r_t$ is the reset gate.\n",
        "- $z_t$ is the update gate.\n",
        "- $\\tilde{h}_t$ is the candidate activation.\n",
        "- $h_t$ is the output.\n",
        "- $\\sigma$ is the sigmoid function.\n",
        "- $\\odot$ is the element-wise multiplication.\n",
        "\n",
        "---\n",
        "\n",
        "## Transformer Attention\n",
        "\n",
        "### Self Attention\n",
        "\n",
        "The self-attention mechanism allows the model to weigh the significance of each part in a sequence based on its content. For a query $Q$, key $K$, and value $V$ set, the attention mechanism is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right) V\n",
        "$$\n",
        "\n",
        "Where $d_k$ is the dimension of the keys.\n",
        "\n",
        "### Multi-head Attention\n",
        "\n",
        "Instead of using one set of attention weights, multi-head attention uses multiple sets, allowing the model to focus on different parts of the input for different tasks or reasons.\n",
        "\n",
        "---\n",
        "\n",
        "## Residual Connections (ResBlocks)\n",
        "\n",
        "Residual connections (or skip connections) allow for the direct flow of gradients during the backpropagation process. If $x$ is the input and $F(x)$ is the output after some layers, the residual connection is:\n",
        "\n",
        "$$\n",
        "\\text{output} = x + F(x)\n",
        "$$\n",
        "\n",
        "This ensures that even as $F(x)$ learns the residuals (or errors), the original input is preserved.\n"
      ],
      "metadata": {
        "id": "GcS9MoG6vXhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlock, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm1d(out_channels)\n",
        "        self.skip = nn.Sequential()\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.skip = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm1d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn(self.conv(x)))\n",
        "        out = out + self.skip(x)\n",
        "        return F.relu(out)\n",
        "class AcousticModel(nn.Module):\n",
        "    def __init__(self, n_input, n_channel, num_res_blocks=1):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(n_input, n_channel, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm1d(n_channel)\n",
        "        self.pool1 = nn.MaxPool1d(2)\n",
        "\n",
        "        # Allow for multiple residual blocks\n",
        "        self.resblocks = nn.Sequential(*[ResBlock(n_channel, n_channel) for _ in range(num_res_blocks)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.resblocks(x)\n",
        "        return x\n",
        "\n",
        "class RecurrentLayers(nn.Module):\n",
        "    def __init__(self, n_channel, hidden_dim, num_gru_layers=1):\n",
        "        super().__init__()\n",
        "        self.gru = nn.GRU(n_channel, hidden_dim, num_layers=num_gru_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, _ = self.gru(x)\n",
        "        return x\n",
        "\n",
        "class nueraspeechASR(nn.Module):\n",
        "    def __init__(self, n_input=1, n_output=35, n_channel=16, hidden_dim=64, dropout_rate=0.4, num_res_blocks=1, num_gru_layers=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.acoustic_model = AcousticModel(n_input, n_channel, num_res_blocks=num_res_blocks)\n",
        "        self.recurrent_layers = RecurrentLayers(n_channel, hidden_dim, num_gru_layers=num_gru_layers)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim*2, n_output)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.acoustic_model(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.recurrent_layers(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc1(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "# Testing the model\n",
        "n_input = 128\n",
        "n_output = 35\n",
        "\n",
        "model = nueraspeechASR(n_input=n_input, n_output=n_output)\n",
        "print(model)\n",
        "\n",
        "# Print number of parameters\n",
        "print(f'The model has {sum(p.numel() for p in model.parameters()):,} trainable parameters')\n",
        "\n",
        "# Test\n",
        "x = torch.randn(1, 128, 8000)\n",
        "OUT = model(x)\n",
        "print(OUT.shape)\n"
      ],
      "metadata": {
        "id": "s5MfeA7a3WIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aiDhhfdA3fbE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Li3m6SMqdY2p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zKs9WPdYUaB"
      },
      "outputs": [],
      "source": [
        "# @title Default title text\n",
        "\n",
        "n_epoch = 10\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "\n",
        "pbar = tqdm(total=len(train_loader.dataset), desc=\"Training Progress\")\n",
        "PATH = \"nueraspeech.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8yIN9wkYUaB"
      },
      "outputs": [],
      "source": [
        "def train(model, epoch, log_interval):\n",
        "    model.train()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.squeeze(1)  # This will remove the single channel dimension, turning [batch_size, 1, 128, 41] into [batch_size, 128, 41]\n",
        "\n",
        "        # Preprocess the data with Mel-spectrogram transform\n",
        "        data = mel_spectrogram_transform(data)\n",
        "\n",
        "        # Apply SpecAugment (only during training)\n",
        "        data = spec_augment(data)\n",
        "        data = data.to(device)\n",
        "\n",
        "\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output.squeeze(), target)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print training stats\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "        # record loss\n",
        "        losses.append(loss.item())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AfXRkUfpEjoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvhCMAKYYUaC"
      },
      "outputs": [],
      "source": [
        "def wer(s1, s2):\n",
        "    \"\"\"\n",
        "    Compute the Word Error Rate between two lists of words.\n",
        "    \"\"\"\n",
        "    b = set(s1 + s2)\n",
        "    word2char = dict(zip(b, range(len(b))))\n",
        "\n",
        "    w1 = [chr(word2char[w]) for w in s1]\n",
        "    w2 = [chr(word2char[w]) for w in s2]\n",
        "\n",
        "    return editdistance.eval(\" \".join(w1), \" \".join(w2)) / len(s2)\n",
        "def cer(s1, s2):\n",
        "    \"\"\"\n",
        "    Compute the Character Error Rate between two lists of words.\n",
        "    \"\"\"\n",
        "    s1 = \" \".join(s1)\n",
        "    s2 = \" \".join(s2)\n",
        "\n",
        "    return editdistance.eval(s1, s2) / len(s2)\n",
        "\n",
        "\n",
        "def number_of_correct(pred, target):\n",
        "    # count number of correct predictions\n",
        "    return pred.squeeze().eq(target).sum().item()\n",
        "\n",
        "\n",
        "def get_likely_index(tensor):\n",
        "    # find most likely label index for each element in the batch\n",
        "    return tensor.argmax(dim=-1)\n",
        "wer_over_epochs = []\n",
        "cer_over_epochs = []\n",
        "correct_predictions_over_epochs = []\n",
        "\n",
        "def test(model, epoch):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total_wer, total_cer, total_samples = 0, 0, 0\n",
        "\n",
        "    for data, target in test_loader:\n",
        "        # Apply Mel-spectrogram transform\n",
        "        data = mel_spectrogram_transform(data)\n",
        "\n",
        "        # Remove channel dimension after applying mel transform\n",
        "        data = data.squeeze(1)  # This will convert [batch_size, 1, 128, 41] into [batch_size, 128, 41]\n",
        "\n",
        "        data = data.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        pred = get_likely_index(output)\n",
        "        correct += number_of_correct(pred, target)\n",
        "\n",
        "        # Compute WER and CER\n",
        "        pred_str = index_to_label(pred)  # Convert the prediction indices to string\n",
        "        target_str = index_to_label(target)  # Convert target indices to string\n",
        "\n",
        "        total_wer += wer(pred_str, target_str)\n",
        "        total_cer += cer(pred_str, target_str)\n",
        "        total_samples += 1\n",
        "\n",
        "        # update progress bar\n",
        "        pbar.update(pbar_update)\n",
        "\n",
        "    avg_wer = total_wer / total_samples\n",
        "    avg_cer = total_cer / total_samples\n",
        "\n",
        "    print(f\"\\nTest Epoch: {epoch}\\tAccuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\")\n",
        "    print(f\"Average WER: {avg_wer:.4f}\\nAverage CER: {avg_cer:.4f}\\n\")\n",
        "\n",
        "    return avg_wer, avg_cer, correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66TkhMppYUaC"
      },
      "outputs": [],
      "source": [
        "log_interval = 20\n",
        "pbar_update = 1 / (len(train_loader) + len(test_loader))\n",
        "losses = []\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "for epoch in range(1, n_epoch + 1):\n",
        "    train(model, epoch, log_interval)\n",
        "    # Evaluate the model\n",
        "    avg_wer, avg_cer, correct_predictions = test(model, epoch)\n",
        "\n",
        "    # Store the metrics for plotting or further analysis\n",
        "    wer_over_epochs.append(avg_wer)\n",
        "    cer_over_epochs.append(avg_cer)\n",
        "    correct_predictions_over_epochs.append(correct_predictions)\n",
        "    scheduler.step()\n",
        "   # Save\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "    print(\"saved\")\n",
        "# Let's plot the training loss versus the number of iteration.\n",
        "# plt.plot(losses);\n",
        "# plt.title(\"training loss\");"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUL3nYYsL9Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "epKEsu3lGi9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IBjroUSRzYrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ud0PZc69I9Fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "01iL6uSYI4iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9GwgFngZvUak"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mau8tq4l8trN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics\n",
        "\n",
        "### Word Error Rate (WER)\n",
        "\n",
        "Word Error Rate (WER) is a standard metric used to measure the performance of an automatic speech recognition system. It represents the ratio of incorrect words to the total number of words in the reference transcription:\n",
        "\n",
        "$$\n",
        "\\text{WER} = \\frac{\\text{Substitutions + Insertions + Deletions}}{\\text{Total number of words in reference}}\n",
        "$$\n",
        "\n",
        "### Character Error Rate (CER)\n",
        "\n",
        "Character Error Rate (CER) is similar to WER but measures errors at the character level. It represents the ratio of incorrect characters to the total number of characters in the reference transcription:\n",
        "\n",
        "$$\n",
        "\\text{CER} = \\frac{\\text{Substitutions + Insertions + Deletions}}{\\text{Total number of characters in reference}}\n",
        "$$\n",
        "\n",
        "### Accuracy - to be implemented\n",
        "\n",
        "Accuracy is a standard metric used to evaluate classification models. It is defined as the ratio of correct predictions to the total number of predictions:\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Number of Correct Predictions}}{\\text{Total Number of Predictions}}\n",
        "$$\n",
        "\n",
        "### Loss\n",
        "\n",
        "The loss function quantifies how well the predicted outputs agree with the actual labels. For classification problems, a common loss function is the negative log-likelihood loss:\n",
        "\n",
        "$$\n",
        "\\text{Loss} = -\\log \\left( \\frac{\\text{Probability of the Correct Class}}{\\text{Sum of Probabilities for All Classes}} \\right)\n",
        "$$\n",
        "\n",
        "These metrics provide a comprehensive evaluation of the model's performance, allowing for better understanding and optimization.\n"
      ],
      "metadata": {
        "id": "lkN8QHKGy_al"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Let's plot the training metrics versus the number of iteration.\n",
        "# WER Plotvimport matplotlib.pyplot as plt\n",
        "epochs = list(range(1, 201))\n",
        "\n",
        "#loss\n",
        "plt.plot(losses)\n",
        "plt.title(\"Training Loss Per Batch\")\n",
        "plt.xlabel(\"Batches\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(correct_predictions_over_epochs, marker='o', label='Number of Correct Predictions')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Number of Correct Predictions')\n",
        "plt.title('Correct Predictions Over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.figure(figsize=(12, 6))\n",
        "# Plot WER# Assuming wer_over_epochs and cer_over_epochs have been populated correctly during training:\n",
        "epochs_range = list(range(1, len(wer_over_epochs) + 1))\n",
        "\n",
        "plt.plot(epochs_range, wer_over_epochs, label='WER', marker='o')\n",
        "\n",
        "plt.plot(epochs_range, cer_over_epochs, label='CER', marker='o')\n",
        "plt.title('WER & CER over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JouJkeHEn23Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "VXUUzeXrtZB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0M7uLxfoYUaC"
      },
      "outputs": [],
      "source": [
        "def predict(tensor):\n",
        "    # Use the model to predict the label of the waveform\n",
        "    tensor = tensor.to(device)\n",
        "    tensor = transform(tensor)\n",
        "    tensor = model(tensor.unsqueeze(0))\n",
        "    tensor = get_likely_index(tensor)\n",
        "    tensor = index_to_label(tensor.squeeze())\n",
        "    return tensor\n",
        "\n",
        "\n",
        "waveform, sample_rate, utterance, *_ = train_set[-1]\n",
        "ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "\n",
        "print(f\"Expected: {utterance}. Predicted: {predict(waveform)}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RtSpxswYUaC"
      },
      "outputs": [],
      "source": [
        "for i, (waveform, sample_rate, utterance, *_) in enumerate(test_set):    output = predict(waveform)\n",
        "if output != utterance:\n",
        "      ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "      print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")\n",
        "\n",
        "else:\n",
        "    print(\"All examples in this dataset were correctly classified!\")\n",
        "    print(\"In this case, let's just look at the last data point\")\n",
        "    ipd.Audio(waveform.numpy(), rate=sample_rate)\n",
        "    print(f\"Data point #{i}. Expected: {utterance}. Predicted: {output}.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z6xOoXaxd2Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sounddevice"
      ],
      "metadata": {
        "id": "m8bcdv57dxpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-b1lnCsyYUaC"
      },
      "outputs": [],
      "source": [
        "import sounddevice as sd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio.transforms as T\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Defining functions\n",
        "def record_audio():\n",
        "    print(\"Recording...\")\n",
        "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1, dtype=np.float32)\n",
        "    sd.wait()\n",
        "    print(\"Recording done.\")\n",
        "    return torch.tensor(audio).squeeze()\n",
        "\n",
        "def live_validate(model, waveform, true_label_text):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Extract features from the given waveform\n",
        "        features = transform(waveform)\n",
        "        features = features.unsqueeze(0)  # Adding batch dimension\n",
        "\n",
        "        # Model forward pass\n",
        "        outputs = model(features)\n",
        "\n",
        "        # Get predicted label\n",
        "        predicted_label_index = outputs.argmax(dim=1).item()\n",
        "        predicted_label_text = labels[predicted_label_index]\n",
        "\n",
        "        # Compute WER and CER\n",
        "        wer_score = wer([true_label_text], [predicted_label_text])\n",
        "        cer_score = cer(true_label_text, predicted_label_text)\n",
        "\n",
        "    return predicted_label_text, wer_score, cer_score\n",
        "\n",
        "# Lists to store metrics for plotting\n",
        "wer_over_epochs = []\n",
        "cer_over_epochs = []\n",
        "loss_over_epochs = []\n",
        "accuracy_over_epochs = []\n",
        "\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "\n",
        "    # Select a random label\n",
        "    true_label_index = random.randint(0, len(labels) - 1)\n",
        "    true_label_text = labels[true_label_index]\n",
        "    print(f\"Please speak the label: {true_label_text}\")\n",
        "\n",
        "    # Record audio\n",
        "    waveform = record_audio()\n",
        "\n",
        "    # Extract features\n",
        "    features = transform(waveform)\n",
        "    features = features.unsqueeze(0)  # Adding batch dimension\n",
        "\n",
        "    # Model forward pass\n",
        "    outputs = model(features)\n",
        "\n",
        "    # Compute loss\n",
        "    true_label_tensor = torch.tensor([true_label_index])  # Convert the true label to tensor\n",
        "    loss = loss_function(outputs.squeeze(0), true_label_tensor)\n",
        "\n",
        "    # Backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute accuracy\n",
        "    pred = outputs.argmax(dim=1, keepdim=True)\n",
        "    correct = pred.eq(true_label_tensor.view_as(pred)).sum().item()\n",
        "    accuracy = correct / len(true_label_tensor)\n",
        "\n",
        "    # Store metrics\n",
        "    loss_over_epochs.append(loss.item())\n",
        "    accuracy_over_epochs.append(accuracy)\n",
        "\n",
        "    # Live validation\n",
        "    print(\"Please provide an audio sample for validation:\")\n",
        "    val_waveform = record_audio()\n",
        "    predicted_label, wer_score, cer_score = live_validate(model, val_waveform, true_label_text)\n",
        "    print(f\"Model's prediction: {predicted_label}\\nWER: {wer_score}\\nCER: {cer_score}\\n\")\n",
        "    wer_over_epochs.append(wer_score)\n",
        "    cer_over_epochs.append(cer_score)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}, Accuracy: {accuracy*100:.2f}%\\n\")\n",
        "\n",
        "# Plot metrics\n",
        "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axs[0, 0].plot(loss_over_epochs, label='Training Loss')\n",
        "axs[0, 0].set_title('Training Loss')\n",
        "axs[0, 1].plot(accuracy_over_epochs, label='Training Accuracy')\n",
        "axs[0, 1].set_title('Training Accuracy')\n",
        "axs[1, 0].plot(wer_over_epochs, label='WER')\n",
        "axs[1, 0].set_title('Word Error Rate (WER)')\n",
        "axs[1, 1].plot(cer_over_epochs, label='CER')\n",
        "axs[1, 1].set_title('Character Error Rate (CER)')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPODYt4gCwn2"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Plot WER and CER\n",
        "plt.plot(wer_over_epochs2, label='WER')\n",
        "plt.plot(cer_over_epochs2, label='CER')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Error Rate')\n",
        "plt.legend()\n",
        "plt.title('Live Validation Metrics')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}